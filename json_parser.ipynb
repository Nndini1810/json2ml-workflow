{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "378573e8-182d-4234-bd25-d8a88f6d7969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7f74b2-670d-401d-aca6-c6cf58e801dd",
   "metadata": {},
   "source": [
    "## JSON Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "89eef326-7b0f-4e8e-a768-6928f9742bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'session_name': 'test',\n",
       " 'session_description': 'test',\n",
       " 'design_state_data': {'session_info': {'project_id': '1',\n",
       "   'experiment_id': 'kkkk-11',\n",
       "   'dataset': 'iris_modified.csv',\n",
       "   'session_name': 'test',\n",
       "   'session_description': 'test'},\n",
       "  'target': {'prediction_type': 'Classification',\n",
       "   'target': 'species',\n",
       "   'type': 'classifiation',\n",
       "   'partitioning': True},\n",
       "  'train': {'policy': 'Split the dataset',\n",
       "   'time_variable': 'sepal_length',\n",
       "   'sampling_method': 'No sampling(whole data)',\n",
       "   'split': 'Randomly',\n",
       "   'k_fold': False,\n",
       "   'train_ratio': 0.8,\n",
       "   'random_seed': 10},\n",
       "  'feature_handling': {'sepal_length': {'feature_name': 'sepal_length',\n",
       "    'is_selected': True,\n",
       "    'feature_variable_type': 'numerical',\n",
       "    'feature_details': {'numerical_handling': 'Keep as regular numerical feature',\n",
       "     'rescaling': 'No rescaling',\n",
       "     'make_derived_feats': False,\n",
       "     'missing_values': 'Impute',\n",
       "     'impute_with': 'Average of values'}},\n",
       "   'sepal_width': {'feature_name': 'sepal_width',\n",
       "    'is_selected': True,\n",
       "    'feature_variable_type': 'numerical',\n",
       "    'feature_details': {'numerical_handling': 'Keep as regular numerical feature',\n",
       "     'rescaling': 'No rescaling',\n",
       "     'make_derived_feats': False,\n",
       "     'missing_values': 'Impute',\n",
       "     'impute_with': 'Average of values'}},\n",
       "   'petal_length': {'feature_name': 'petal_length',\n",
       "    'is_selected': True,\n",
       "    'feature_variable_type': 'numerical',\n",
       "    'feature_details': {'numerical_handling': 'Keep as regular numerical feature',\n",
       "     'rescaling': 'No rescaling',\n",
       "     'make_derived_feats': False,\n",
       "     'missing_values': 'Impute',\n",
       "     'impute_with': 'Average of values'}},\n",
       "   'petal_width': {'feature_name': 'petal_width',\n",
       "    'is_selected': False,\n",
       "    'feature_variable_type': 'numerical',\n",
       "    'feature_details': {'numerical_handling': 'Keep as regular numerical feature',\n",
       "     'rescaling': 'No rescaling',\n",
       "     'make_derived_feats': False,\n",
       "     'missing_values': 'Impute',\n",
       "     'impute_with': 'Average of values'}},\n",
       "   'species': {'feature_name': 'species',\n",
       "    'is_selected': True,\n",
       "    'feature_variable_type': 'text',\n",
       "    'feature_details': {'text_handling': 'Tokenize and hash',\n",
       "     'hash_columns': 0}}},\n",
       "  'algorithms': {'RandomForestClassifier': {'model_name': 'Random Forest Classifier',\n",
       "    'is_selected': True,\n",
       "    'min_trees': 10,\n",
       "    'max_trees': 30,\n",
       "    'feature_sampling_statergy': 'Default',\n",
       "    'min_depth': 20,\n",
       "    'max_depth': 30,\n",
       "    'min_samples_per_leaf_min_value': 5,\n",
       "    'min_samples_per_leaf_max_value': 50,\n",
       "    'parallelism': 0},\n",
       "   'RandomForestRegressor': {'model_name': 'Random Forest Regressor',\n",
       "    'is_selected': False,\n",
       "    'min_trees': 10,\n",
       "    'max_trees': 20,\n",
       "    'feature_sampling_statergy': 'Default',\n",
       "    'min_depth': 20,\n",
       "    'max_depth': 25,\n",
       "    'min_samples_per_leaf_min_value': 5,\n",
       "    'min_samples_per_leaf_max_value': 10,\n",
       "    'parallelism': 0},\n",
       "   'LinearRegression': {'model_name': 'LinearRegression',\n",
       "    'is_selected': False,\n",
       "    'parallelism': 2,\n",
       "    'min_iter': 30,\n",
       "    'max_iter': 50,\n",
       "    'min_regparam': 0.5,\n",
       "    'max_regparam': 0.8,\n",
       "    'min_elasticnet': 0.5,\n",
       "    'max_elasticnet': 0.8},\n",
       "   'LogisticRegression': {'model_name': 'LogisticRegression',\n",
       "    'is_selected': False,\n",
       "    'parallelism': 2,\n",
       "    'min_iter': 30,\n",
       "    'max_iter': 50,\n",
       "    'min_regparam': 0.5,\n",
       "    'max_regparam': 0.8,\n",
       "    'min_elasticnet': 0.5,\n",
       "    'max_elasticnet': 0.8},\n",
       "   'RidgeRegression': {'model_name': 'RidgeRegression',\n",
       "    'is_selected': False,\n",
       "    'regularization_term': 'Specify values to test',\n",
       "    'min_iter': 30,\n",
       "    'max_iter': 50,\n",
       "    'min_regparam': 0.5,\n",
       "    'max_regparam': 0.8},\n",
       "   'LassoRegression': {'model_name': 'Lasso Regression',\n",
       "    'is_selected': False,\n",
       "    'regularization_term': 'Specify values to test',\n",
       "    'min_iter': 30,\n",
       "    'max_iter': 50,\n",
       "    'min_regparam': 0.5,\n",
       "    'max_regparam': 0.8},\n",
       "   'ElasticNetRegression': {'model_name': 'Lasso Regression',\n",
       "    'is_selected': False,\n",
       "    'regularization_term': 'Specify values to test',\n",
       "    'min_iter': 30,\n",
       "    'max_iter': 50,\n",
       "    'min_regparam': 0.5,\n",
       "    'max_regparam': 0.8,\n",
       "    'min_elasticnet': 0.5,\n",
       "    'max_elasticnet': 0.8},\n",
       "   'xg_boost': {'model_name': 'XG Boost',\n",
       "    'is_selected': False,\n",
       "    'use_gradient_boosted_tree': True,\n",
       "    'dart': True,\n",
       "    'tree_method': '',\n",
       "    'random_state': 0,\n",
       "    'max_num_of_trees': 0,\n",
       "    'early_stopping': True,\n",
       "    'early_stopping_rounds': 2,\n",
       "    'max_depth_of_tree': [56, 89],\n",
       "    'learningRate': [89, 76],\n",
       "    'l1_regularization': [77],\n",
       "    'l2_regularization': [78],\n",
       "    'gamma': [68],\n",
       "    'min_child_weight': [67],\n",
       "    'sub_sample': [67],\n",
       "    'col_sample_by_tree': [67],\n",
       "    'replace_missing_values': False,\n",
       "    'parallelism': 0},\n",
       "   'DecisionTreeRegressor': {'model_name': 'Decision Tree',\n",
       "    'is_selected': False,\n",
       "    'min_depth': 4,\n",
       "    'max_depth': 7,\n",
       "    'use_gini': False,\n",
       "    'use_entropy': True,\n",
       "    'min_samples_per_leaf': [12, 6],\n",
       "    'use_best': True,\n",
       "    'use_random': True},\n",
       "   'DecisionTreeClassifier': {'model_name': 'Decision Tree',\n",
       "    'is_selected': True,\n",
       "    'min_depth': 4,\n",
       "    'max_depth': 7,\n",
       "    'use_gini': False,\n",
       "    'use_entropy': True,\n",
       "    'min_samples_per_leaf': [12, 6],\n",
       "    'use_best': True,\n",
       "    'use_random': False},\n",
       "   'SVM': {'model_name': 'Support Vector Machine',\n",
       "    'is_selected': False,\n",
       "    'linear_kernel': True,\n",
       "    'rep_kernel': True,\n",
       "    'polynomial_kernel': True,\n",
       "    'sigmoid_kernel': True,\n",
       "    'c_value': [566, 79],\n",
       "    'auto': True,\n",
       "    'scale': True,\n",
       "    'custom_gamma_values': True,\n",
       "    'tolerance': 7,\n",
       "    'max_iterations': 7},\n",
       "   'KNN': {'model_name': 'KNN',\n",
       "    'is_selected': False,\n",
       "    'k_value': [78],\n",
       "    'distance_weighting': True,\n",
       "    'neighbour_finding_algorithm': 'Automatic',\n",
       "    'random_state': 0,\n",
       "    'p_value': 0},\n",
       "   'neural_network': {'model_name': 'Neural Network',\n",
       "    'is_selected': False,\n",
       "    'hidden_layer_sizes': [67, 89],\n",
       "    'activation': '',\n",
       "    'alpha_value': 0,\n",
       "    'max_iterations': 0,\n",
       "    'convergence_tolerance': 0,\n",
       "    'early_stopping': True,\n",
       "    'solver': 'ADAM',\n",
       "    'shuffle_data': True,\n",
       "    'initial_learning_rate': 0,\n",
       "    'automatic_batching': True,\n",
       "    'beta_1': 0,\n",
       "    'beta_2': 0,\n",
       "    'epsilon': 0,\n",
       "    'power_t': 0,\n",
       "    'momentum': 0,\n",
       "    'use_nesterov_momentum': False}}}}"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_json_config(file_path):\n",
    "    \"\"\"\n",
    "    Load JSON configuration from the provided file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Loaded JSON configuration.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            config = json.load(f)\n",
    "        return config\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON from file '{file_path}': {e}\")\n",
    "        return None\n",
    "\n",
    "config=load_json_config('/Users/macbook/Documents/algoparams_from_ui1.json')\n",
    "config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf84d9c3-5766-45ab-ae58-034f0b0bb33d",
   "metadata": {},
   "source": [
    "## Identify Data and Problem Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b428d703-4c24-4863-82f7-0a192e9b9e22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def identify_data(json_config):\n",
    "    \"\"\"\n",
    "    Identify data file, target variable, and problem type from JSON configuration.\n",
    "    Create a DataFrame from the provided CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - json_config (dict): JSON configuration containing data information.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame or None: DataFrame created from the CSV file, or None if there's an error.\n",
    "    - str or None: Target variable name, or None if not found.\n",
    "    - str or None: Problem type (classification or regression), or None if not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract data file and target variable from JSON\n",
    "        data_file = json_config['design_state_data']['session_info']['dataset']\n",
    "        target_variable = json_config['design_state_data']['target']['target']\n",
    "        \n",
    "        # Create DataFrame from CSV file\n",
    "        data = pd.read_csv(data_file)\n",
    "        \n",
    "        # Identify problem type\n",
    "        if json_config['design_state_data']['target']['prediction_type'] == 'Classification':\n",
    "            problem_type = 'classification'\n",
    "        else:\n",
    "            problem_type = 'regression'\n",
    "\n",
    "        return data, target_variable, problem_type\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Key not found in JSON configuration: {e}\")\n",
    "        return None, None, None\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Data file '{data_file}' not found.\")\n",
    "        return None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "data, target_variable, problem_type = identify_data(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f16f9666-b721-4711-97c8-7f5435c0113d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "b824053e-220e-4d4d-aaac-b7016646d806",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'species'"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "3f6852b0-3db8-4a80-938d-02290df29c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'classification'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_type  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53ae0b0-c263-46a4-965f-7077daa1a738",
   "metadata": {},
   "source": [
    "## Feature Selection:\n",
    "\n",
    "- Identify the features to be used based on the \"is_selected\" attribute.\n",
    "- Create X (features) and y (target) from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "60706124-57d6-4be5-bdb8-8d302620ceb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_X_Y_dataframe(datafile, config):\n",
    "    # Step 1: Load the CSV file\n",
    "    df = pd.read_csv(datafile)\n",
    "    \n",
    "    # Step 2: Parse the JSON configuration\n",
    "    feature_handling = config.get(\"feature_handling\", {})\n",
    "    target = config.get(\"target\", {})\n",
    "    \n",
    "    # Identify selected features and target variable\n",
    "    selected_features = [feature for feature, details in feature_handling.items() if details.get(\"is_selected\", False)]\n",
    "    target_variable = target.get(\"target\", None)\n",
    "    \n",
    "    # Step 3: Create X and Y DataFrames\n",
    "    if target_variable is not None and selected_features:\n",
    "        X_df = df[selected_features]\n",
    "        Y_df = df[[target_variable]]\n",
    "        return X_df, Y_df\n",
    "    else:\n",
    "        print(\"Target variable or selected features not found in the configuration.\")\n",
    "        return None, None\n",
    "datafile = \"iris_modified.csv\"\n",
    "config = {\n",
    "    \"feature_handling\": {\n",
    "        \"sepal_length\": {\"is_selected\": True},\n",
    "        \"sepal_width\": {\"is_selected\": True},\n",
    "        \"petal_length\": {\"is_selected\": True},\n",
    "        \"petal_width\": {\"is_selected\": True},\n",
    "        \"species\": {\"is_selected\": False }\n",
    "    },\n",
    "    \"target\": {\n",
    "        \"target\": \"species\"\n",
    "    }\n",
    "}\n",
    "\n",
    "X_df, Y_df = create_X_Y_dataframe(datafile, config)\n",
    "X_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "050cd380-e3a8-48f5-8602-ca0e4539119d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       species\n",
       "0  Iris-setosa\n",
       "1  Iris-setosa"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea95e19-0417-451d-a2d6-06dc76fd179d",
   "metadata": {},
   "source": [
    "## Data spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "9429a3ea-4b03-4997-a13d-0713ca9f1a57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_data(X, Y, train_ratio, random_seed):\n",
    "    \"\"\"\n",
    "    Split the data into training and validation sets based on the given split ratio and random seed value.\n",
    "\n",
    "    Args:\n",
    "    - X (DataFrame): The DataFrame containing the features.\n",
    "    - Y (DataFrame): The DataFrame containing the target variable.\n",
    "    - train_ratio (float): The ratio of the training set.\n",
    "    - random_seed (int): Random seed value for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - X_train (DataFrame): The training features.\n",
    "    - X_val (DataFrame): The validation features.\n",
    "    - Y_train (DataFrame): The training target variable.\n",
    "    - Y_val (DataFrame): The validation target variable.\n",
    "    \"\"\"\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X, Y, train_size=train_ratio, random_state=random_seed)\n",
    "    return X_train, X_val, Y_train, Y_val\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = split_data(X_df, Y_df, train_ratio=0.8, random_seed=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "891ce4dd-a67f-4c48-9f5a-88a77e23a04e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>6.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length  sepal_width  petal_length  petal_width\n",
       "58           6.6          2.9           4.6          1.3\n",
       "97           6.2          2.9           4.3          1.3"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f2d652fe-4b13-4024-9c64-510196c34e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            species\n",
       "58  Iris-versicolor\n",
       "97  Iris-versicolor"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecf8995-a684-4c36-8488-cc79ee65c10b",
   "metadata": {},
   "source": [
    "## Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "57a00283-b63f-46e4-bf2a-2faae066a65e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_missing_values(data, config):\n",
    "    \"\"\"\n",
    "    Handle missing values in the DataFrame based on the provided configuration.\n",
    "\n",
    "    Args:\n",
    "    - data (DataFrame): The DataFrame containing the dataset.\n",
    "    - config (dict): The configuration containing feature details.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: The DataFrame with missing values handled according to the configuration.\n",
    "    \"\"\"\n",
    "    features_config = config.get(\"feature_handling\", {})\n",
    "    for feature_name, feature_config in features_config.items():\n",
    "        if feature_config.get(\"missing_values\") == \"Impute\":\n",
    "            impute_with = feature_config.get(\"feature_details\", {}).get(\"impute_with\", \"Average of values\")\n",
    "            if impute_with == \"Average of values\":\n",
    "                data[feature_name] = data[feature_name].fillna(data[feature_name].mean())\n",
    "            # Add additional handling for other impute_with options if needed\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6252a248-cc0e-402f-ba7b-b95c1b09da8c",
   "metadata": {},
   "source": [
    "## Encode features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "f745593b-8be1-41e2-886c-414da7d1c0b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_features(X_train, X_test, Y_train, Y_test, config):\n",
    "    \"\"\"\n",
    "    Encode features and target variable in the training and testing data based on the provided configuration.\n",
    "\n",
    "    Args:\n",
    "    - X_train (DataFrame): The training data.\n",
    "    - X_test (DataFrame): The testing data.\n",
    "    - Y_train (DataFrame): The target variable of the training data.\n",
    "    - Y_test (DataFrame): The target variable of the testing data.\n",
    "    - config (dict): The configuration containing feature details.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: The training data with features encoded according to the configuration.\n",
    "    - DataFrame: The testing data with features encoded according to the configuration.\n",
    "    - Series: The encoded target variable of the training data.\n",
    "    - Series: The encoded target variable of the testing data.\n",
    "    \"\"\"\n",
    "    features_config = config.get(\"feature_handling\", {})\n",
    "    ohe_columns = []\n",
    "    oe_columns = []\n",
    "\n",
    "    for feature_name, feature_config in features_config.items():\n",
    "        feature_variable_type = feature_config.get(\"feature_variable_type\")\n",
    "        \n",
    "        if feature_variable_type == \"categorical\" or feature_variable_type == \"text\":\n",
    "            ohe_columns.append(feature_name)\n",
    "        elif feature_variable_type == \"ordinal\":\n",
    "            oe_columns.append(feature_name)\n",
    "\n",
    "    # One-hot encoding for categorical and text features\n",
    "    if ohe_columns:\n",
    "        ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        ohe.fit(X_train[ohe_columns])\n",
    "        X_train_ohe = pd.DataFrame(ohe.transform(X_train[ohe_columns]), columns=ohe.get_feature_names(ohe_columns), index=X_train.index)\n",
    "        X_test_ohe = pd.DataFrame(ohe.transform(X_test[ohe_columns]), columns=ohe.get_feature_names(ohe_columns), index=X_test.index)\n",
    "        X_train = pd.concat([X_train.drop(ohe_columns, axis=1), X_train_ohe], axis=1)\n",
    "        X_test = pd.concat([X_test.drop(ohe_columns, axis=1), X_test_ohe], axis=1)\n",
    "\n",
    "    # Ordinal encoding for ordinal features\n",
    "    if oe_columns:\n",
    "        oe = OrdinalEncoder()\n",
    "        oe.fit(X_train[oe_columns])\n",
    "        X_train[oe_columns] = oe.transform(X_train[oe_columns])\n",
    "        X_test[oe_columns] = oe.transform(X_test[oe_columns])\n",
    "\n",
    "    # Label encoding for remaining categorical features\n",
    "    le = LabelEncoder()\n",
    "    for col in X_train.select_dtypes(include=['object']).columns:\n",
    "        X_train[col] = le.fit_transform(X_train[col])\n",
    "        X_test[col] = le.transform(X_test[col])\n",
    "\n",
    "    # Encode target variable for training data\n",
    "    problem_type = config.get(\"target\", {}).get(\"prediction_type\")\n",
    "    if problem_type == \"Classification\":\n",
    "        le_target = LabelEncoder()\n",
    "        Y_train_encoded = le_target.fit_transform(Y_train)\n",
    "    elif problem_type == \"Regression\":\n",
    "        oe_target = OrdinalEncoder()\n",
    "        Y_train_encoded = oe_target.fit_transform(Y_train.values.reshape(-1, 1))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported problem type in configuration:\", problem_type)\n",
    "\n",
    "    # Encode target variable for testing data\n",
    "    if problem_type == \"Classification\":\n",
    "        Y_test_encoded = le_target.transform(Y_test)\n",
    "    elif problem_type == \"Regression\":\n",
    "        Y_test_encoded = oe_target.transform(Y_test.values.reshape(-1, 1))\n",
    "\n",
    "    return X_train, X_test, Y_train_encoded, Y_test_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "493eb6ba-f328-4dda-a8cb-1f826abd08e1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/macbook/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "X_train_encoded, X_test_encoded, Y_train_encoded,Y_test_encoded= encode_features(X_train, X_val, Y_train,Y_val ,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0aff39d9-1213-405d-a9f7-1c8cd707ca57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   encoded_target\n",
       "0               1\n",
       "1               1"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_encoded.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0b962d6c-1832-4eae-81de-4ada257b4f06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   encoded_target\n",
       "0               1\n",
       "1               2\n",
       "2               0"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_encoded.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "35cfe394-9571-436e-b59f-e2423b4d5d91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rescale_features_after_tts(X_train, X_test, config):\n",
    "    \"\"\"\n",
    "    Rescale numerical features in the training and testing data based on the provided configuration.\n",
    "\n",
    "    Args:\n",
    "    - X_train (DataFrame): The training data.\n",
    "    - X_test (DataFrame): The testing data.\n",
    "    - config (dict): The configuration containing feature rescaling details.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: The training data with numerical features rescaled according to the configuration.\n",
    "    - DataFrame: The testing data with numerical features rescaled according to the configuration.\n",
    "    \"\"\"\n",
    "    for feature_name, feature_config in config.items():\n",
    "        if feature_config.get('feature_variable_type') == 'numerical':\n",
    "            rescaling_method = feature_config['feature_details'].get('rescaling')\n",
    "            if rescaling_method == 'Standardization':\n",
    "                scaler = StandardScaler()\n",
    "            elif rescaling_method == 'Min-Max Scaling':\n",
    "                scaler = MinMaxScaler()\n",
    "            elif rescaling_method == 'No rescaling':\n",
    "                continue\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported rescaling method for feature '{feature_name}': {rescaling_method}\")\n",
    "            \n",
    "            # Fit scaler on training data and transform both training and testing data\n",
    "            scaler.fit(X_train[[feature_name]])\n",
    "            X_train[feature_name] = scaler.transform(X_train[[feature_name]])\n",
    "            X_test[feature_name] = scaler.transform(X_test[[feature_name]])\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "X_train_rescaled, X_test_rescaled = rescale_features_after_tts(X_train, X_val, config['feature_handling'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64644d21-84c2-4d1b-a926-e6d6cbb4d8ce",
   "metadata": {},
   "source": [
    "## Model Building:\n",
    "\n",
    "- Identify the selected algorithm from the JSON.\n",
    "- Extract hyperparameters for the selected algorithm.\n",
    "- Use GridSearchCV for hyperparameter tuning.\n",
    "- Train the model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "3a2dd06e-62af-44be-b11d-d764db74a024",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def parse_json_and_build_models(json_data):\n",
    "    selected_models = []\n",
    "    for model_name, model_config in json_data['design_state_data']['algorithms'].items():\n",
    "        if model_config.get('is_selected', False):\n",
    "            # Extract hyperparameters from model configuration\n",
    "            hyperparameters = {}\n",
    "            for key, value in model_config.items():\n",
    "                if key in ['n_estimators', 'max_depth',\n",
    "                           'min_samples_per_leaf_min_value', 'min_samples_per_leaf_max_value',\n",
    "                           'regularization_term', 'max_iter', 'min_regparam', 'max_regparam']:\n",
    "                    hyperparameters[key] = value\n",
    "            \n",
    "            # Define parameter grid for GridSearchCV based on extracted hyperparameters\n",
    "            param_grid = {}\n",
    "            for key, value in hyperparameters.items():\n",
    "                if isinstance(value, list):\n",
    "                    param_grid[key] = value\n",
    "                elif isinstance(value, int):\n",
    "                    param_grid[key] = [value]\n",
    "                elif isinstance(value, dict):\n",
    "                    param_grid[key] = range(value['min'], value['max'] + 1)\n",
    "            \n",
    "            # Create model instance\n",
    "            if model_name == 'RandomForestClassifier':\n",
    "                model = RandomForestClassifier(random_state=42)\n",
    "            elif model_name == 'DecisionTreeClassifier':\n",
    "                model = DecisionTreeClassifier(random_state=42)\n",
    "            elif model_name == 'LogisticRegression':\n",
    "                model = LogisticRegression(random_state=42)\n",
    "            \n",
    "            # Append model name, model instance, and parameter grid to selected_models list\n",
    "            selected_models.append((model_name, model, param_grid))\n",
    "                \n",
    "            \n",
    "    return selected_models\n",
    "\n",
    "# Load JSON data (replace this with your JSON data)\n",
    "json_data = load_json_config('/Users/macbook/Documents/algoparams_from_ui1.json')\n",
    "\n",
    "# Parse JSON and build selected models\n",
    "selected_models = parse_json_and_build_models(json_data)\n",
    "\n",
    "# Perform hyperparameter tuning using GridSearchCV\n",
    "best_models = []\n",
    "for model_name, model, param_grid in selected_models:\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    if model_name == \"LogisticRegression\":\n",
    "        grid_search.fit(X_train_rescaled, Y_train_encoded)\n",
    "    else:\n",
    "        grid_search.fit(X_train_rescaled, np.ravel(Y_train_encoded))\n",
    "    best_models.append((model_name, grid_search.best_estimator_, grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "a8164dc7-b1da-4450-9ba7-e0c49f879154",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_classification_model(model, X_test, y_test):\n",
    "    # Predict the target values\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Calculate classification report\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    return cm, report\n",
    "\n",
    "def evaluate_regression_model(model, X_test, y_test):\n",
    "    # Predict the target values\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate R-squared\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Calculate Adjusted R-squared\n",
    "    n = X_test.shape[0]\n",
    "    p = X_test.shape[1]\n",
    "    adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    return r2, adj_r2, rmse\n",
    "\n",
    "# Evaluation for classification models\n",
    "for model_name, model, _ in best_models:\n",
    "    if model_name in ['RandomForestClassifier', 'DecisionTreeClassifier', 'LogisticRegression']:\n",
    "        print(f\"Evaluation for {model_name}:\")\n",
    "        cm, report = evaluate_classification_model(model, X_test_rescaled, Y_test_encoded)\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm)\n",
    "        print(\"Classification Report:\")\n",
    "        print(report)\n",
    "        print()\n",
    "\n",
    "# Evaluation for regression models\n",
    "for model_name, model, _ in best_models:\n",
    "    if model_name in ['RandomForestRegressor', 'DecisionTreeRegressor', 'LinearRegression']:\n",
    "        print(f\"Evaluation for {model_name}:\")\n",
    "        r2, adj_r2, rmse = evaluate_regression_model(model, X_test_rescaled, Y_test_encoded)\n",
    "        print(f\"R-squared: {r2}\")\n",
    "        print(f\"Adjusted R-squared: {adj_r2}\")\n",
    "        print(f\"RMSE: {rmse}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bd2d48-9dc2-49d4-a4f7-8eeb6502e29a",
   "metadata": {},
   "source": [
    "## Model Evaluation:\n",
    "\n",
    "- Evaluate the trained model using appropriate evaluation metrics based on the problem type (classification or regression).\n",
    "- Print the evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "6721f579-4934-42eb-93a3-3caf36cc8c2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "Decision Tree Classifier:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.92      0.85      0.88        13\n",
      "           2       0.75      0.86      0.80         7\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.89      0.90      0.89        30\n",
      "weighted avg       0.91      0.90      0.90        30\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_classification_metrics(model, X_test, y_test):\n",
    "    # Predict the target values\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print classification metrics for each model\n",
    "print(\"Random Forest Classifier:\")\n",
    "print_classification_metrics(rf_grid_search.best_estimator_, X_test_rescaled, Y_test_encoded)\n",
    "\n",
    "print(\"\\nDecision Tree Classifier:\")\n",
    "print_classification_metrics(dt_grid_search.best_estimator_, X_test_rescaled, Y_test_encoded)\n",
    "\n",
    "print(\"\\nLogistic Regression:\")\n",
    "print_classification_metrics(lr_grid_search.best_estimator_, X_test_rescaled, Y_test_encoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
